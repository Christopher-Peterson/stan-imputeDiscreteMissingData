functions{
  /// Functions to marginalize out missing categorical covariates for imputation
  /// Written by Christopher R. Peterson
  int dmd_pow2(int k){ // returns 2^k
    int out;
    out <- 1;
    for(i in 1:k)
      out <- out * 2;
    return out;
  }
  // take a row with d missing data points and return a 
  // vector of all possible combinations of linear predictors
  vector dmd_etas(row_vector x, vector beta, int[] missingPos){
    int d;
    int k;
    int outSize;
    vector[dmd_pow2(size(missingPos))] out;
    d <- size(missingPos);
    k <- cols(x);
    outSize <- dmd_pow2(d);
    { 
      row_vector[d] posState; //<lower=0, upper=1>
      row_vector[d] twos; //<lower=2, upper=outSize>
      row_vector[k] tmpX;
      //Initialize
        tmpX <- x;
        for(i in 1:d)
          twos[i] <- 2.0^i;
      // create each output
      for(i in 1:outSize) {
        for(j in 1:d) // increment posState; this is conceptually similar to using bitwise operators for binary masking
          posState[j] <- step(j/twos[j] == floor(j/twos[j])); // This is essentially a modulo function
        tmpX[missingPos] <- posState;
        out[i] <- tmpX * beta;
      }
    }
    return out;
}
  
  // Take the p parameter for each missing value in a row and 
  // return the joint distribution, expressed as a vector.  
  // These should match with the linear predictors generated by dmd_etas()
  // Return values are on log scale
  vector dmd_probs(row_vector p, int[] missingPos){
    int d;
    int outSize;
    vector[dmd_pow2(size(missingPos))] out;
    d <- size(missingPos);
      outSize <- dmd_pow2(d);
    { row_vector[d] posState; //<lower=0, upper=1>
      row_vector[d] posSign; //  -1 if posState is 1, 1 if posState is 0; //<lower=0, upper=1>
      row_vector[d] twos; //<lower=2, upper=outSize>
      row_vector[d] tmpP;
      //Initialize
        for(i in 1:d)
          twos[i] <- 2.0^i;
      // create each output
      for(i in 1:outSize) {
        for(j in 1:d) // increment posState; this is conceptually similar to using bitwise operators for binary masking
          posState[j] <- step(j/twos[j] == floor(j/twos[j]));
        posSign <- -2*posState + 1;
        tmpP <- posState + posSign .* p;
        out[i] <- sum(log(tmpP));
      }
    }
    return out;
}
  
  //returns normal_log for a single row with some missing data
  real dmd_normal_single_log(real y, row_vector x, real sigma, vector beta, row_vector p,  int[] missingPos){
    int d;
    real out;
    int vecSize;
    d <- size(missingPos);
    vecSize <- dmd_pow2(d);
    {
      vector[vecSize] lprobs;
      vector[vecSize] etas;
      vector[vecSize] lpVec;
      lprobs <- dmd_probs(p, missingPos);
      etas <- dmd_etas(x, beta, missingPos);
      for(i in 1:vecSize)
        lpVec[i] <- normal_log(y, etas[i], sigma) + lprobs[i];
      out <- log_sum_exp(lpVec);
    }
    return out;
}
  
  // This function assumes everything is fully hierarchical, and all lengths are n.
  real dmd_normal_log(vector y, matrix x, vector sigma, vector[] beta, row_vector p, 
    int[] missingRows, /*Which rows have missing data; must be sorted*/
    int[] missingPerRow, /*How many on that row are missing*/ 
    int[] wholeRows, /*which rows have all data*/
    int[] missingPos ){
    int n; // rows
    int k; // columns
    int d; // missing values
    real lp_out;
    int nRowsMissing;
    int nRowsWhole;
    
    n <- rows(y);
    k <- cols(x);
    d <- size(missingPos);
    nRowsMissing <- size(missingRows);
    nRowsWhole <- n - nRowsMissing;
    {// In this block: take the logLikelihood of all rows that are NOT missing
      vector[nRowsWhole] eta;
      
      for(i in 1:nRowsWhole)
        eta[i] <- x[wholeRows[i]] * beta[wholeRows[i]];
      
      lp_out <- normal_log(y[wholeRows], eta, sigma[wholeRows]);
    }
    {// In this block: use a for loop to calculate the lp of each other row, then add it to lp_out
      int start;
      int stop;
      start <- 1;
      stop <- 0;
      for(i in 1:nRowsMissing){
        stop <- stop + missingPerRow[i];
        lp_out <- lp_out + dmd_normal_single_log(y[missingRows[i]], x[missingRows[i]], 
          sigma[missingRows[i]], beta[missingRows[i]], p[start:stop], missingPos[start:stop]);
        start <- start + missingPerRow[i];
        
      }
    }
    return lp_out;
}
  row_vector Phi_rvec(row_vector x){
    row_vector[cols(x)] out;
    for(i in 1:cols(x))
      out[i] <- Phi(x[i]);
    return out;
  }
}
data{
  int n;
  int<lower=2> k; // num Covariates, including intercept
  int nMissing;  // Total number of missing categorical covariates
  int nMissingRows; // Number of rows with at least one missing value
//  matrix[n, k] x; // column 1 should be all 1's.; this is dropped for the fully latent variable version
  vector[n] y;
  int<lower=1, upper=n> missingRows[nMissingRows]; // These should be sorted from lowest to highest
  int<lower=1, upper=k-1> missingPerRow[nMissingRows]; // Number of missing columns in the missing row with the same index
  int<lower=1, upper=n> missingPosN[nMissing]; // row position of missing variable; these should be sorted from lowest to highest.
  int<lower=2, upper=k> missingPosK[nMissing]; // column position of missing variable, corresponding to missingPosN
  int<lower=1, upper=n>  wholeRows[n - nMissingRows]; // Rows with no missing covariates; not sure if 0 is actually a valid number
 
  int nZero;  // number of zero's
  int nOne;  // number of ones.
  int<lower=1, upper=n> onePosN[nOne]; // row position of missing variable; these should be sorted from lowest to highest.
  int<lower=1, upper=k> onePosK[nOne]; // column position of missing variable, corresponding to missingPosN
  int<lower=1, upper=n> zeroPosN[nZero]; // row position of missing variable; these should be sorted from lowest to highest.
  int<lower=1, upper=k> zeroPosK[nZero]; // column position of missing variable, corresponding to missingPosN

  real LKJParam; 
}
transformed data{
  vector[k-1] muZero;
  matrix[n,k] x;
  for(i in 1:n)
    x[i,1]<- 1;
  for(i in 1:nOne)
    x[onePosN[i], onePosK[i]] <- 1;
  for(i in 1:nZero)
    x[zeroPosN[i], zeroPosK[i]] <- 0;
  for(i in 1:nMissing)
    x[missingPosN[i], missingPosK[i]] <- 100;
  
  muZero <- rep_vector(0, k-1);
}
parameters{
  vector[k] beta; // Assume no hierarchy
  real<lower=0> sigma;
#  cholesky_factor_corr[k-1] L;
  row_vector[nMissing] xProbsLogit;
#  vector[k-1] muZero;
#  vector<upper=-2>[nZero] xZero;
#  vector<lower=2>[nOne] xOne;
}
transformed parameters{
  row_vector[nMissing] xProbs;
  xProbs <- Phi_rvec(xProbsLogit);
}
model{
  row_vector[k-1] xCor[n];
  vector[k] betaFull[n];
#  for(i in 1:n)
#    xCor[i] <- x[i, 2:k] * 2 - 1; // Put it on a scale of [-1,1] instead of [0,1], for better correlation
  for(i in 1:nMissing)
    xCor[missingPosN[i], missingPosK[i]-1] <- xProbsLogit[i];
  for(i in 1:nZero)
    xCor[zeroPosN[i], zeroPosK[i]-1] <- -3;#xZero[i];
  for(i in 1:nOne)
    xCor[onePosN[i], onePosK[i]-1] <- 3;#xOne[i];

  for(i in 1:n)
    betaFull[i] <- beta;
  #L ~ lkj_corr_cholesky(LKJParam);
  beta ~ normal(0, 3);
  sigma ~ cauchy(0,2.5);
  muZero ~ normal(0,1);
 # xCor ~ multi_normal_cholesky(muZero, L);
xProbsLogit ~ normal(0,4);
  y ~ dmd_normal(x, rep_vector(sigma,n), betaFull, xProbs, missingRows, missingPerRow, wholeRows, missingPosK);
}