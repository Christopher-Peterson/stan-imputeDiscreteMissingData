file.exists("~/.ssh/id_rsa.pub")
rstan:::rstudio_stanc("~/Documents/Files/Research/Stats Projects/discreteMissingData/discreteMissingDataTestHier.stan")
rstan:::rstudio_stanc("~/Documents/Files/Research/Stats Projects/discreteMissingData/discreteMissingDataTestHier.stan")
rstan:::rstudio_stanc("~/Documents/Files/Research/Stats Projects/discreteMissingData/discreteMissingDataTestHier.stan")
library(shinystan)
library(rstan)
library(mvtnorm)
rcor <- function(n, d, eta = 1, chol = FALSE, forceList=FALSE){
k = choose(d,2)
out = lapply(1:n, function(i) {
z = matrix(0, d,d)
z[upper.tri(z)] = rbeta(k, eta, eta) * 2 - 1  ## Constrain to (-1,1)
# Many have to convert to lower.tri if cholesky factors are to be done properly
## Calculate determinant
z = z + diag(d)
w = matrix(0, d,d)
#Convert z into cholesky factor
w[1,] = z[1,]
w[1,1] = 1
for(i in 2:d){ ## See section 56.11 of Stan manual v2.9 (chokesly Correlation Transforms) for this.
for(j in i:d)
w[i,j] = z[i,j] * sqrt(1-sum(w[1:(i-1),j]^2))
}
if(chol==FALSE) w = t(w) %*% w
w
})
if(n==1 && forceList==FALSE) out = out[[1]]
out
}   # random correlation; eta is LKJ parameter
n = 500
nClust = 5
nPerClust = n/nClust
k = 3  # not including intercept
nMissing = n * k * .15
clustID = rep(1:nClust, each = nPerClust)
set.seed(2)
propCols = round(gtools::rdirichlet(1, rep(3,k)) *nMissing)
missingPosN = unlist(lapply(1:k, function(i) sample.int(500, size = propCols[i])))
nMissing <- length(missingPosN)
orderN = order(missingPosN)
missingPosN = sort(missingPosN)
missingPosK = rep(1:k, times = propCols)+1
missingPosK = missingPosK[orderN]
missingRows = unique(missingPosN)
nMissingRows = length(missingRows)
missingPerRow = as.vector(table(missingPosN))
wholeRows = setdiff(1:n, missingRows)
betaHier = c(3, 8, -4, -7)
L = rcor(1,k+1, 3, chol=TRUE)
betaSD = c(2, .3, 1, 1.8)
Omega = tcrossprod(diag(betaSD) %*% t(L))
beta = rmvnorm(nClust,betaHier, sigma=Omega)
sigma = 1
# Make x vary by level.
# This will require x to be generated as a normal distribution then "stepped"
baseXMeans = rnorm(k)
clustXMeans = rmvnorm(nClust, baseXMeans)
x = cbind(1, do.call(rbind, lapply(1:n, function(i) rnorm(k, clustXMeans[clustID[i],]))) > 0)
y = sapply(1:n, function(i) rnorm(1, x[i,] %*% t(beta[clustID[i],]), sigma))
k = k+1 # update to include intercept
library(rstan)
LKJParam = 2
## Now, we'll need to calcuate the helper indices for x.  These are:
##   nClustMissing, the Number of clusters with missing data, and
##   missingClustID[nMissing], a vector of  which of the above clusters
##    corresponds to which data point.
##    We might also want to cinsider a clusterTranslate[nClustMissing], which
##    ties the index of the missing cluster to the base cluster index
##
# Figure out how many clusters are missing
whichClustMissing <- unique(clustID[missingRows])
nClustMissing <- length(whichClustMissing)
missingIDTranslate = rep(0, nClust); missingIDTranslate[whichClustMissing] <- 1:nClustMissing
missingClustID <-   missingIDTranslate[clustID[missingPosN]]
xTmp = x
for(i in 1:nMissing)
xTmp[missingPosN[i],missingPosK[i]]<- 100000
nZero = sum(xTmp==0);  # number of zeros
nOne = sum(xTmp[,-1]==1);  # number of ones.
onePosN = unlist(lapply(2:k, function(i) which(xTmp[,i]==1)))   # row position of missing variable; these should be sorted from lowest to highest.
onePosK = unlist(lapply(2:k, function(i) rep(i, sum(xTmp[,i]==1))))    # column position of missing variable, corresponding to missingPosN
zeroPosN = unlist(lapply(2:k, function(i) which(xTmp[,i]==0)))   # row position of missing variable; these should be sorted from lowest to highest.
zeroPosK = unlist(lapply(2:k, function(i) rep(i, sum(xTmp[,i]==0))))   # column position of missing variable, corresponding to missingPosN
rm(xTmp)
fit = stan("discreteMissingDataTestHier.stan", chains = 1, iter = 10)
fit = stan("discreteMissingDataTestHier.stan", chains = 1, iter = 10)
fit = stan(fit = fit, chains = 5, cores=5, iter = 1000, control=list(adapt_delta=.9, max_treedepth = 13))
fit = stan("discreteMissingDataTestHier.stan", chains = 1, iter = 10)
fit = stan(fit = fit, chains = 5, cores=5, iter = 1000, control=list(adapt_delta=.9, max_treedepth = 13))
fit = stan(fit = fit, chains = 5, cores=5, iter = 1000, control=list(adapt_delta=.99, max_treedepth = 13))
launch_shinystan(fit)
print(fit,"beta")
beta
print(fit,"beta")
birthYear = floor(runif(n, 0,9))
birthYear = floor(runif(n, 0,9)) + 1840
deathsPerDecade = c(1,0,4,4,5,3,2,7,1,2,1,0)
deathsPerDecade = c(1,0,4,4,5,3,2,7,1,2,1,0)
length(deathsPerDecade)
sum(deathsPerDecade)
((0:11) * 10)[deathsPerDecade]
((0:11) * 10)
rep((0:11) * 10, each = deathsPerDecade)
sapply(0:11, function(i) rep(i * 10, deathsPerDecade))
sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1]))
length(deathsPerDecade)
min(numeric(0), 0)
min(numeric(0), 5)
min(numeric(0), 5)
sapply(0:11, function(i) pmin(rep(i * 10, deathsPerDecade[i+1]), 0))
sapply(0:11, function(i) pmax(rep(i * 10, deathsPerDecade[i+1]), 0))
unlist(sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1])))
length(unlist(sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1]))))
ages = floor(runif(n, 0, 9)) + length(unlist(sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1]))))
ages
deathYear = birthYear + ages
deathYear
sex = sample(c("M","F"), n, TRUE)
sex
data.frame(birthYear, deathYear, sex)
data.1840 = data.frame(birthYear, deathYear, sex)
# 1870's
birthYear = floor(runif(n, 0,9)) + 1870
deathsPerDecade = c(1,0,4,4,5,3,2,7,1,2,1,0)
ages = floor(runif(n, 0, 9)) + length(unlist(sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1]))))
deathYear = birthYear + ages
sex = sample(c("M","F"), n, TRUE)
data.1870 = data.frame(birthYear, deathYear, sex)
deathsPerDecade = c(1,0,0,2,1,4,8,9,4,1)
sum(deathsPerDecade)
birthYear = floor(runif(n, 0,9)) + 1840
deathsPerDecade = c(1,0,0,2,1,4,8,9,4,1)
ages = floor(runif(n, 0, 9)) + length(unlist(sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1]))))
deathYear = birthYear + ages
sex = sample(c("M","F"), n, TRUE)
data.1840 = data.frame(birthYear, deathYear, sex)
birthYear = floor(runif(n, 0,9)) + 1840
length(deathsPerDecade)
deathsPerDecade = c(1,0,0,2,1,4,8,9,4,1, 0, 0)
ages = floor(runif(n, 0, 9)) + length(unlist(sapply(0:11, function(i) rep(i * 10, deathsPerDecade[i+1]))))
deathYear = birthYear + ages
sex = sample(c("M","F"), n, TRUE)
data.1840 = data.frame(birthYear, deathYear, sex)
setwd("~/Documents/Files/Teaching")
setwd("~/Documents/Files/Teachingasdf")
?write.csv
write.csv(data.1940, "1840Cohort.csv")
write.csv(data.1840, "1840Cohort.csv")
write.csv(data.1870, "1870Cohort.csv")
update.packages("rstanarm")
rstan:::rstudio_stanc("~/Documents/Files/Research/Stats Projects/discreteMissingData/hierNoMissingTest.stan")
rstan:::rstudio_stanc("~/Documents/Files/Research/Stats Projects/discreteMissingData/hierNoMissingTest.stan")
library(shinystan)
library(rstan)
library(mvtnorm)
rcor <- function(n, d, eta = 1, chol = FALSE, forceList=FALSE){
k = choose(d,2)
out = lapply(1:n, function(i) {
z = matrix(0, d,d)
z[upper.tri(z)] = rbeta(k, eta, eta) * 2 - 1  ## Constrain to (-1,1)
# Many have to convert to lower.tri if cholesky factors are to be done properly
## Calculate determinant
z = z + diag(d)
w = matrix(0, d,d)
#Convert z into cholesky factor
w[1,] = z[1,]
w[1,1] = 1
for(i in 2:d){ ## See section 56.11 of Stan manual v2.9 (chokesly Correlation Transforms) for this.
for(j in i:d)
w[i,j] = z[i,j] * sqrt(1-sum(w[1:(i-1),j]^2))
}
if(chol==FALSE) w = t(w) %*% w
w
})
if(n==1 && forceList==FALSE) out = out[[1]]
out
}   # random correlation; eta is LKJ parameter
n = 1500
nClust = 3
nPerClust = n/nClust
k = 3  # not including intercept
nMissing = n * k * 0
clustID = rep(1:nClust, each = nPerClust)
set.seed(2)
betaHier = c(3, 8, -4, -7)
L = rcor(1,k+1, 3, chol=TRUE)
betaSD = c(2, .3, 1, 1.8)
Omega = tcrossprod(diag(betaSD) %*% t(L))
beta = rmvnorm(nClust,betaHier, sigma=Omega)
sigma = 1
set.seed(3)
betaHier = c(3, 8, -4, -7)
L = rcor(1,k+1, 3, chol=TRUE)
betaSD = c(2, .3, 1, 1.8)
Omega = tcrossprod(diag(betaSD) %*% t(L))
beta = rmvnorm(nClust,betaHier, sigma=Omega)
sigma = 1
baseXMeans = rnorm(k)
clustXMeans = rmvnorm(nClust, baseXMeans)
x = cbind(1, do.call(rbind, lapply(1:n, function(i) rnorm(k, clustXMeans[clustID[i],]))) > 0)
y = sapply(1:n, function(i) rnorm(1, x[i,] %*% t(beta[clustID[i],]), sigma))
k = k+1 # update to include intercept
LKJParam = 2
xTmp = x
nZero = sum(xTmp==0);  # number of zeros
nOne = sum(xTmp[,-1]==1);  # number of ones.
onePosN = unlist(lapply(2:k, function(i) which(xTmp[,i]==1)))   # row position of missing variable; these should be sorted from lowest to highest.
onePosK = unlist(lapply(2:k, function(i) rep(i, sum(xTmp[,i]==1))))    # column position of missing variable, corresponding to missingPosN
zeroPosN = unlist(lapply(2:k, function(i) which(xTmp[,i]==0)))   # row position of missing variable; these should be sorted from lowest to highest.
zeroPosK = unlist(lapply(2:k, function(i) rep(i, sum(xTmp[,i]==0))))   # column position of missing variable, corresponding to missingPosN
fit = stan("hierNoMissingTest.stan", chains = 1, iter = 10)
getwd
getwd()
setwd("~/Documents/Files/R")
setwd("~/Documents/Files/R*")
setwd("/home/peterson/Documents/Files/Research/Stats Projects/discreteMissingData")
fit = stan("hierNoMissingTest.stan", chains = 1, iter = 10)
fit = stan(fit = fit,seed=2, chains = 2, iter = 500, control=list(adapt_delta=.9, max_treedepth = 13))
launch_shinystan(fit)
print(fit, "beta")
beta
fit = stan("hierNoMissingTest.stan", chains = 1, iter = 10)
fit = stan(fit = fit,seed=2, chains = 2, iter = 500, control=list(adapt_delta=.9, max_treedepth = 13))
print(fit, "beta")
head(x)
head(y)
