/// Functions to marginalize out missing categorical covariates for imputation
/// Written by Christopher R. Peterson

// take a row with d missing data points and return a vector of all possible combinations of linear predictors
vector dmd_etas(row_vector x, vector beta, int[] missingPos){
  int d;
  int k;
  int outSize;
  vector[2^size(missingPos)] out;
  d <- size(missingPos);
  k <- cols(x);
  outSize <- 2^d;
  { 
    row_vector<lower=0, upper=1>[d] posState;
    row_vector<lower=2, upper=outSize>[d] twos;
    row_vector[k] tmpX;
    //Initialize
      tmpX <- x;
      for(i in 1:d)
        twos[i] <- 2.0^i;
    // create each output
    for(i in 1:outSize) {
      for(j in 1:d) // increment posState; this is conceptually similar to using bitwise operators for binary masking
        posState[j] <- step(i/twos[i] == floor(i/twos[i]))
      tmpX[missingPos] <- posState;
      out[i] <- tmpX * beta;
    }
  }
  return out;
}

// Take the p parameter for each missing value in a row and get the joint distribution, expressed as a vector.  
// These should match with the linear predictors generated by dmd_etas()
// Return values are on log scale
vector dmd_probs(row_vector p, int[] missingPos){
  int d;
  int outSize;
  vector[2^size(missingPos)] out;
  d <- size(missingPos);
    outSize <- 2^d;
  { row_vector<lower=0, upper=1>[d] posState;
    row_vector<lower=0, upper=1>[d] posSign; //  -1 if posState is 1, 1 if posState is 0;
    row_vector<lower=2, upper=outSize>[d] twos;
    row_vector[d] tmpP;
    //Initialize
      for(i in 1:d)
        twos[i] <- 2.0^i;
    // create each output
    for(i in 1:outSize) {
      for(j in 1:d) // increment posState; this is conceptually similar to using bitwise operators for binary masking
        posState[j] <- step(i/twos[i] == floor(i/twos[i]))
      posSign <- -2*posState + 1;
      tmpP <- posState + posSign .* p;
      out[i] <- sum(log(tmpP));
    }
  }
  return out;
}

//returns normal_log for a single row with some missing data
real dmd_normal_single_log(real y, row_vector x, real sigma, vector beta, row_vector p,  int[] missingPos){
  int d;
  real out;
  int vecSize;
  d <- size(missingPos);
  vecSize <- 2^d;
  {
    vector[vecSize] lprobs;
    vector[vecSize] etas;
    real[vecSize] lpVec;
    lprobs <- dmd_probs(p, missingPos);
    etas <- dmd_etas(x, beta, missingPos);
    for(i in 1:vecSize)
      lpVec <- normal_log(y, etas[i], sigma) + lprobs[i];
    out <- log_sum_exp(lpVec);
  }
  return out;
}

// This function assumes everything is fully hierarchical, and all lengths are n.
real dmd_normal_log(vector y, row_vector[] x, vector sigma, vector[] beta, vector p, 
  int[] missingRows, /*Which rows have missing data; must be sorted*/
  int[] missingPerRow, /*How many on that row are missing*/, int[] wholeRows, /*which rows have all data*/
  int[] missingPos ){
  int n; // rows
  int k; // columns
  int d; // missing values
  real lp_out;
  int nRowsMissing;
  int nRowsWhole;
  
  n <- rows(y);
  k <- cols(x[1]);
  d <- size(missingPos);
  nRowsMissing <- size(missingRows);
  nRowsWhole <- n - nRowsMissing;
  {// In this block: take the logLikelihood of all rows that are NOT missing
    vector[nRowsWhole] eta;
    
    for(i in 1:nRowsWhole)
      eta[i] <- x[wholeRows[i]] * beta[wholeRows[i]];
    
    lp_out <- normal_log(y[wholeRows], eta, sigma[wholeRows]);
  }
  {// In this block: use a for loop to calculate the lp of each other row, then add it to lp_out
    int start;
    int stop;
    start <- 1;
    for(i in 1:nRowsMissing){
      stop <- start + missingPerRow[i];
      lp_out <- lp_out + dmd_normal_single_log(y[missingRows[i]], x[missingRows[i]], 
        sigma[missingRows[i]], beta[missingRows[i]], missingPos[start:stop])
      start <- stop + 1;
    }
  }
  return lp_out;
}